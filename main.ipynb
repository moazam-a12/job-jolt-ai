{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8909f95-446f-4348-ba84-bd5a92253f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.3 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: requests==2.32.3 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: google-generativeai==0.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.8.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests==2.32.3->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests==2.32.3->-r requirements.txt (line 2)) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests==2.32.3->-r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests==2.32.3->-r requirements.txt (line 2)) (2024.12.14)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai==0.8.3->-r requirements.txt (line 3)) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai==0.8.3->-r requirements.txt (line 3)) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai==0.8.3->-r requirements.txt (line 3)) (2.177.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai==0.8.3->-r requirements.txt (line 3)) (2.40.3)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai==0.8.3->-r requirements.txt (line 3)) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai==0.8.3->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai==0.8.3->-r requirements.txt (line 3)) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai==0.8.3->-r requirements.txt (line 3)) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai==0.8.3->-r requirements.txt (line 3)) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core->google-generativeai==0.8.3->-r requirements.txt (line 3)) (1.70.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai==0.8.3->-r requirements.txt (line 3)) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai==0.8.3->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai==0.8.3->-r requirements.txt (line 3)) (4.9.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai==0.8.3->-r requirements.txt (line 3)) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai==0.8.3->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai==0.8.3->-r requirements.txt (line 3)) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai==0.8.3->-r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai==0.8.3->-r requirements.txt (line 3)) (2.20.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.3->-r requirements.txt (line 3)) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.3->-r requirements.txt (line 3)) (1.71.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai==0.8.3->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.8.3->-r requirements.txt (line 3)) (0.4.8)\n",
      "Dependencies installed, libraries imported, and Gemini API key configured.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Set Gemini API key (replace 'YOUR_GEMINI_API_KEY' with your actual key)\n",
    "os.environ['GOOGLE_API_KEY'] = 'PutYourAPIKeyHere'\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Set base directory\n",
    "BASE_DIR = Path.cwd() / '/Users/moazam_a12/AI-Powered Interview Question Generator'\n",
    "\n",
    "print(\"Dependencies installed, libraries imported, and Gemini API key configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71534a66-7b19-4d41-91e4-c241c05dba27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions in dataset: 1167\n",
      "Unique questions in dataset: 186\n",
      "Unique categories in question bank: ['machine learning', 'data science', 'deep learning', 'behavior']\n",
      "Machine Learning questions: 14\n",
      "Data Science questions: 3\n",
      "Deep Learning questions: 114\n",
      "Behavioral questions: 55\n",
      "Preprocessed data saved to /Users/moazam_a12/AI-Powered Interview Question Generator/utils/preprocessed_data.json\n",
      "Processed 131 technical questions\n",
      "Processed 55 behavioral questions\n",
      "Processed 997 job descriptions\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import load_question_bank, load_job_descriptions, extract_keywords, save_preprocessed_data\n",
    "\n",
    "# Define paths\n",
    "QUESTION_BANK_PATH = BASE_DIR / 'data' / 'updated_coding_interview_question_bank.csv'\n",
    "JOB_DESCRIPTIONS_PATH = BASE_DIR / 'data' / 'job_descriptions.csv'\n",
    "OUTPUT_PATH = BASE_DIR / 'utils' / 'preprocessed_data.json'\n",
    "\n",
    "# Define category column\n",
    "CATEGORY_COLUMN = 'category'\n",
    "\n",
    "# Load and process question bank and job descriptions\n",
    "questions = load_question_bank(QUESTION_BANK_PATH, CATEGORY_COLUMN)\n",
    "jobs = load_job_descriptions(JOB_DESCRIPTIONS_PATH)\n",
    "\n",
    "if questions is not None and jobs is not None:\n",
    "    # Save preprocessed data\n",
    "    save_preprocessed_data(questions, jobs, OUTPUT_PATH)\n",
    "    \n",
    "    # Calculate summary\n",
    "    total_technical = sum(len(questions['technical'][subcat]) for subcat in questions['technical'])\n",
    "    total_behavioral = len(questions['behavioral'])\n",
    "    print(f\"Processed {total_technical} technical questions\")\n",
    "    print(f\"Processed {total_behavioral} behavioral questions\")\n",
    "    print(f\"Processed {len(jobs)} job descriptions\")\n",
    "else:\n",
    "    print(\"Failed to preprocess data. Check input files or preprocess.py.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e78b2b36-1600-49f5-a326-3473e90cbcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question sets saved to /Users/moazam_a12/AI-Powered Interview Question Generator/output/interview_questions.json\n",
      "\n",
      "Sample question set for Upper Hand:\n",
      "{\n",
      "  \"job_title\": \"Internship - Machine Learning Engineer & Data Science\",\n",
      "  \"company_name\": \"Upper Hand\",\n",
      "  \"seniority_level\": \"Internship\",\n",
      "  \"technical_questions\": [\n",
      "    {\n",
      "      \"id\": 1083,\n",
      "      \"question\": \" How do you preprocess text in NLP\",\n",
      "      \"difficulty\": \"Easy\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 1163,\n",
      "      \"question\": \" Describe two ways to visualize features of a CNN in an image classification task\",\n",
      "      \"difficulty\": \"Medium\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 1146,\n",
      "      \"question\": \" Why Sigmoid or Tanh is not preferred to be used as the activation function in the hidden layer of the neural network\",\n",
      "      \"difficulty\": \"Medium\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 1143,\n",
      "      \"question\": \" What can go wrong if we use a linear activation instead of ReLU\",\n",
      "      \"difficulty\": \"Medium\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 1107,\n",
      "      \"question\": \" For infrequent/rare words which among CBOW and SkipGram should be used for wordvec training\",\n",
      "      \"difficulty\": \"Medium\"\n",
      "    }\n",
      "  ],\n",
      "  \"behavioral_questions\": [\n",
      "    {\n",
      "      \"id\": 1018,\n",
      "      \"question\": \"What are your outside interests?\",\n",
      "      \"difficulty\": \"Hard\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 1055,\n",
      "      \"question\": \"Have you consider starting your own business?\",\n",
      "      \"difficulty\": \"Hard\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 1050,\n",
      "      \"question\": \"What do you worry about?\",\n",
      "      \"difficulty\": \"Hard\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Define paths\n",
    "PREPROCESSED_PATH = BASE_DIR / 'utils' / 'preprocessed_data.json'\n",
    "OUTPUT_QUESTIONS_PATH = BASE_DIR / 'output'\n",
    "OUTPUT_QUESTIONS_PATH.mkdir(exist_ok=True)\n",
    "QUESTION_SETS_PATH = OUTPUT_QUESTIONS_PATH / 'interview_questions.json'\n",
    "\n",
    "def select_questions(questions, job_keywords, num_technical=5, num_behavioral=3):\n",
    "    \"\"\"Select relevant questions based on job keywords.\"\"\"\n",
    "    # Select technical questions\n",
    "    technical_questions = []\n",
    "    for subcat in questions['technical']:\n",
    "        if subcat in job_keywords or any(keyword in subcat for keyword in job_keywords):\n",
    "            technical_questions.extend(questions['technical'][subcat])\n",
    "    \n",
    "    # Filter by difficulty (prioritize Easy/Medium for internships)\n",
    "    easy_medium = [q for q in technical_questions if q['difficulty'].lower() in ['easy', 'medium']]\n",
    "    hard = [q for q in technical_questions if q['difficulty'].lower() == 'hard']\n",
    "    selected_technical = random.sample(easy_medium, min(num_technical, len(easy_medium))) if easy_medium else []\n",
    "    if len(selected_technical) < num_technical and hard:\n",
    "        selected_technical.extend(random.sample(hard, min(num_technical - len(selected_technical), len(hard))))\n",
    "    \n",
    "    # Select behavioral questions\n",
    "    behavioral_questions = random.sample(questions['behavioral'], min(num_behavioral, len(questions['behavioral']))) if questions['behavioral'] else []\n",
    "    \n",
    "    return selected_technical, behavioral_questions\n",
    "\n",
    "# Load preprocessed data\n",
    "try:\n",
    "    with open(PREPROCESSED_PATH, 'r') as f:\n",
    "        preprocessed_data = json.load(f)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading preprocessed data: {e}\")\n",
    "    preprocessed_data = {'questions': {'technical': {}, 'behavioral': []}, 'jobs': []}\n",
    "\n",
    "questions = preprocessed_data['questions']\n",
    "jobs = preprocessed_data['jobs']\n",
    "\n",
    "# Generate question sets for each job\n",
    "question_sets = []\n",
    "for job in jobs:\n",
    "    job_title = job['job_title']\n",
    "    company_name = job['company_name']\n",
    "    seniority_level = job['seniority_level']\n",
    "    keywords = job['keywords']\n",
    "    \n",
    "    # Select questions from bank\n",
    "    technical_questions, behavioral_questions = select_questions(questions, keywords)\n",
    "    \n",
    "    # Create question set\n",
    "    question_set = {\n",
    "        'job_title': job_title,\n",
    "        'company_name': company_name,\n",
    "        'seniority_level': seniority_level,\n",
    "        'technical_questions': technical_questions[:5],\n",
    "        'behavioral_questions': behavioral_questions[:3]\n",
    "    }\n",
    "    question_sets.append(question_set)\n",
    "\n",
    "# Save question sets\n",
    "with open(QUESTION_SETS_PATH, 'w') as f:\n",
    "    json.dump(question_sets, f, indent=2)\n",
    "print(f\"Question sets saved to {QUESTION_SETS_PATH}\")\n",
    "\n",
    "# Print sample question set for Upper Hand\n",
    "for q_set in question_sets:\n",
    "    if q_set['company_name'] == 'Upper Hand':\n",
    "        print(\"\\nSample question set for Upper Hand:\")\n",
    "        print(json.dumps(q_set, indent=2))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "520a4f55-4b48-4c72-88fb-d52edb2cde83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define chatbot helper functions\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import re\n",
    "\n",
    "def parse_user_input(user_input):\n",
    "    \"\"\"Use Gemini to parse user input, with keyword fallback if API fails.\"\"\"\n",
    "    # Keyword-based fallback\n",
    "    def keyword_parse(input_text):\n",
    "        input_lower = input_text.lower()\n",
    "        intent = \"unknown\"\n",
    "        company = None\n",
    "        role = None\n",
    "        \n",
    "        if any(word in input_lower for word in ['interview', 'prep', 'prepare']):\n",
    "            intent = \"prepare for interview\"\n",
    "        elif any(word in input_lower for word in ['more', 'additional', 'another']):\n",
    "            intent = \"more questions\"\n",
    "        elif 'tip' in input_lower:\n",
    "            intent = \"interview tips\"\n",
    "        elif any(word in input_lower for word in ['hi', 'hello', 'hey']):\n",
    "            intent = \"greeting\"\n",
    "        elif any(word in input_lower for word in ['quit', 'exit']):\n",
    "            intent = \"quit\"\n",
    "        \n",
    "        # Extract company\n",
    "        if 'upper hand' in input_lower:\n",
    "            company = \"Upper Hand\"\n",
    "        \n",
    "        # Extract role\n",
    "        roles = ['machine learning', 'data science', 'ml engineer', 'data scientist']\n",
    "        for r in roles:\n",
    "            if r in input_lower:\n",
    "                role = r.title()\n",
    "                break\n",
    "        \n",
    "        return {\"intent\": intent, \"company\": company, \"role\": role}\n",
    "    \n",
    "    # Try Gemini API\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following user input and extract:\n",
    "        - Intent: What the user wants (e.g., 'prepare for interview', 'more questions', 'interview tips', 'greeting', 'quit')\n",
    "        - Company: Any mentioned company name (e.g., 'Upper Hand') or None\n",
    "        - Role: Any mentioned job role (e.g., 'Machine Learning Engineer', 'Data Science') or None\n",
    "        Input: \"{user_input}\"\n",
    "        Return a JSON object: {{\"intent\": \"string\", \"company\": \"string or null\", \"role\": \"string or null\"}}\n",
    "        \"\"\"\n",
    "        response = model.generate_content(prompt)\n",
    "        parsed = json.loads(response.text.strip('```json\\n```'))\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        if \"429\" in str(e):\n",
    "            print(\"Oops, hit the API limit. Using backup parsing. Check your quota at https://ai.google.dev/gemini-api/docs/rate-limits.\")\n",
    "        return keyword_parse(user_input)\n",
    "\n",
    "def generate_questions(job_description, keywords, num_technical=0, num_behavioral=0):\n",
    "    \"\"\"Generate additional questions using Gemini API.\"\"\"\n",
    "    # Fallback if job_description is empty\n",
    "    if not job_description:\n",
    "        default_technical = [\n",
    "            {\"id\": \"default_1\", \"question\": \"Explain the difference between supervised and unsupervised learning.\", \"difficulty\": \"Easy\", \"category\": \"Machine Learning\"},\n",
    "            {\"id\": \"default_2\", \"question\": \"What is overfitting, and how can you prevent it?\", \"difficulty\": \"Medium\", \"category\": \"Machine Learning\"}\n",
    "        ][:num_technical]\n",
    "        default_behavioral = [\n",
    "            {\"id\": \"default_1\", \"question\": \"Tell me about a time you worked in a team to solve a problem.\", \"difficulty\": \"Easy\", \"category\": \"Behavioral\"},\n",
    "            {\"id\": \"default_2\", \"question\": \"How do you handle conflicting priorities?\", \"difficulty\": \"Easy\", \"category\": \"Behavioral\"}\n",
    "        ][:num_behavioral]\n",
    "        return default_technical, default_behavioral\n",
    "\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "    technical_prompt = f\"\"\"\n",
    "    Generate {num_technical} technical interview questions for an intern-level role with the following job description:\n",
    "    {job_description}\n",
    "    Focus on skills: {', '.join(keywords)}.\n",
    "    Questions should be Easy or Medium difficulty, concise, and role-specific.\n",
    "    Format as a JSON list: [{{\\\"id\\\": \\\"generated_X\\\", \\\"question\\\": \\\"Question text\\\", \\\"difficulty\\\": \\\"Easy/Medium\\\", \\\"category\\\": \\\"Appropriate category\\\"}}]\n",
    "    \"\"\"\n",
    "    behavioral_prompt = f\"\"\"\n",
    "    Generate {num_behavioral} behavioral interview questions for an intern-level role with the following job description:\n",
    "    {job_description}\n",
    "    Focus on teamwork, communication, and motivation.\n",
    "    Format as a JSON list: [{{\\\"id\\\": \\\"generated_X\\\", \\\"question\\\": \\\"Question text\\\", \\\"difficulty\\\": \\\"Easy\\\", \\\"category\\\": \\\"Behavioral\\\"}}]\n",
    "    \"\"\"\n",
    "    \n",
    "    generated_technical = []\n",
    "    generated_behavioral = []\n",
    "    \n",
    "    try:\n",
    "        if num_technical > 0:\n",
    "            technical_response = model.generate_content(technical_prompt)\n",
    "            generated_technical = json.loads(technical_response.text.strip('```json\\n```'))\n",
    "            for i, q in enumerate(generated_technical):\n",
    "                q['id'] = f\"generated_technical_{i}\"\n",
    "        if num_behavioral > 0:\n",
    "            behavioral_response = model.generate_content(behavioral_prompt)\n",
    "            generated_behavioral = json.loads(behavioral_response.text.strip('```json\\n```'))\n",
    "            for i, q in enumerate(generated_behavioral):\n",
    "                q['id'] = f\"generated_behavioral_{i}\"\n",
    "        return generated_technical, generated_behavioral\n",
    "    except Exception as e:\n",
    "        if \"429\" in str(e):\n",
    "            print(\"Oops, hit the API limit. Can't generate new questions right now.\")\n",
    "        return [], []\n",
    "\n",
    "def get_interview_tips(role=None):\n",
    "    \"\"\"Generate interview tips using Gemini API.\"\"\"\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "    role_text = f\" for a {role} role\" if role else \"\"\n",
    "    prompt = f\"\"\"\n",
    "    Provide 3 concise interview tips{role_text}.\n",
    "    Focus on preparation, communication, and technical skills.\n",
    "    Format as a JSON list: [\\\"Tip 1\\\", \\\"Tip 2\\\", \\\"Tip 3\\\"]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        tips = json.loads(response.text.strip('```json\\n```'))\n",
    "        return tips\n",
    "    except Exception as e:\n",
    "        if \"429\" in str(e):\n",
    "            print(\"Oops, hit the API limit. Using default tips.\")\n",
    "        return [\"Review common concepts.\", \"Practice clear communication.\", \"Prepare questions for the interviewer.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb9adc9f-db7b-4055-b79d-3a1d93f220f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data loaded successfully.\n",
      "Question sets loaded successfully.\n",
      "Data loaded successfully. Ready to run the chatbot in the next cell.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load data and initialize chatbot context\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Define paths\n",
    "BASE_DIR = Path.cwd()\n",
    "QUESTION_SETS_PATH = BASE_DIR / 'output' / 'interview_questions.json'\n",
    "PREPROCESSED_PATH = BASE_DIR / 'utils' / 'preprocessed_data.json'\n",
    "UPDATED_QUESTION_SETS_PATH = BASE_DIR / 'output' / 'updated_interview_questions.json'\n",
    "\n",
    "# Load preprocessed data for job descriptions\n",
    "try:\n",
    "    with open(PREPROCESSED_PATH, 'r') as f:\n",
    "        preprocessed_data = json.load(f)\n",
    "    print(\"Preprocessed data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading preprocessed data: {e}\")\n",
    "    preprocessed_data = {'jobs': []}\n",
    "\n",
    "# Load question sets from Cell 3\n",
    "try:\n",
    "    with open(QUESTION_SETS_PATH, 'r') as f:\n",
    "        question_sets = json.load(f)\n",
    "    print(\"Question sets loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading question sets: {e}\")\n",
    "    question_sets = []\n",
    "\n",
    "# Initialize context\n",
    "current_company = None\n",
    "current_role = None\n",
    "\n",
    "print(\"Data loaded successfully. Ready to run the chatbot in the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d215cee-83ef-44c2-aa42-8cc87c25fc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Interview Prep Chatbot! 👩‍💻\n",
      "Say something like 'I need to prepare for an Upper Hand interview' or 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hey!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hey there! Ready to prep for an interview? Tell me something like 'I need to prepare for an Upper Hand interview' or 'interview tips'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Need prep so bad!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I need a bit more info! Which company or role are you preparing for? (e.g., 'Upper Hand' or 'Data Science')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  I applied to sales in Ibex?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I didn't quite understand. Try something like 'I need to prepare for an Upper Hand interview', 'more questions', or 'interview tips'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  need prep!! I'm not prepared for my interview!! HELP ME!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I need a bit more info! Which company or role are you preparing for? (e.g., 'Upper Hand' or 'Data Science')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Well, it's for an Internship for ML?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No question set found for 'Machine Learning Intern'. Trying to generate new questions...\n",
      "New question set saved to /Users/moazam_a12/AI-Powered Interview Question Generator/output/updated_interview_questions.json\n",
      "\n",
      "Here's your generated question set:\n",
      "{\n",
      "  \"job_title\": \"Machine Learning Intern\",\n",
      "  \"company_name\": \"Unknown Company\",\n",
      "  \"seniority_level\": \"Unknown\",\n",
      "  \"technical_questions\": [\n",
      "    {\n",
      "      \"id\": \"default_1\",\n",
      "      \"question\": \"Explain the difference between supervised and unsupervised learning.\",\n",
      "      \"difficulty\": \"Easy\",\n",
      "      \"category\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"default_2\",\n",
      "      \"question\": \"What is overfitting, and how can you prevent it?\",\n",
      "      \"difficulty\": \"Medium\",\n",
      "      \"category\": \"Machine Learning\"\n",
      "    }\n",
      "  ],\n",
      "  \"behavioral_questions\": [\n",
      "    {\n",
      "      \"id\": \"default_1\",\n",
      "      \"question\": \"Tell me about a time you worked in a team to solve a problem.\",\n",
      "      \"difficulty\": \"Easy\",\n",
      "      \"category\": \"Behavioral\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"default_2\",\n",
      "      \"question\": \"How do you handle conflicting priorities?\",\n",
      "      \"difficulty\": \"Easy\",\n",
      "      \"category\": \"Behavioral\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "You mentioned Machine Learning Intern. What next? Try 'more technical questions', 'more behavioral questions', 'interview tips', or specify a company/role.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Well, I'd appreciate any tips I can get?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interview tips:\n",
      "- Prepare by deeply understanding common ML algorithms (linear regression, logistic regression, decision trees, etc.) and their underlying assumptions, trade-offs, and practical applications. Practice explaining them simply.\n",
      "- Communicate your thought process clearly and concisely. When problem-solving, articulate your approach, assumptions, and any challenges you encounter. Don't be afraid to ask clarifying questions.\n",
      "- Showcase your technical skills through projects. Be ready to discuss the details of your projects, including the data used, the models implemented, the evaluation metrics, and the lessons learned. Emphasize quantifiable results.\n",
      "\n",
      "You mentioned Machine Learning Intern. What next? Try 'more technical questions', 'more behavioral questions', 'interview tips', or specify a company/role.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye! Best of luck with your interviews! 👑\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Run the interactive chatbot\n",
    "print(\"Welcome to the Interview Prep Chatbot! 👩‍💻\")\n",
    "print(\"Say something like 'I need to prepare for an Upper Hand interview' or 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    \n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Goodbye! Best of luck with your interviews! 👑\")\n",
    "        break\n",
    "    \n",
    "    # Parse input\n",
    "    parsed_input = parse_user_input(user_input)\n",
    "    intent = parsed_input['intent']\n",
    "    company = parsed_input['company']\n",
    "    role = parsed_input['role']\n",
    "    \n",
    "    # Update context\n",
    "    if company:\n",
    "        current_company = company\n",
    "    if role:\n",
    "        current_role = role\n",
    "    \n",
    "    if intent == 'prepare for interview':\n",
    "        # Prompt for company/role if None\n",
    "        if not company and not role:\n",
    "            print(\"\\nI need a bit more info! Which company or role are you preparing for? (e.g., 'Upper Hand' or 'Data Science')\")\n",
    "            continue\n",
    "        \n",
    "        # Find matching question set\n",
    "        matched_set = None\n",
    "        for q_set in question_sets:\n",
    "            if (current_company and current_company.lower() in q_set['company_name'].lower()) or \\\n",
    "               (current_role and current_role.lower() in q_set['job_title'].lower()):\n",
    "                matched_set = q_set\n",
    "                break\n",
    "        \n",
    "        if matched_set:\n",
    "            print(f\"\\nHere's your question set for {matched_set['company_name']} ({matched_set['job_title']}):\")\n",
    "            print(json.dumps(matched_set, indent=2))\n",
    "        else:\n",
    "            print(f\"\\nNo question set found for '{current_company or current_role}'. Trying to generate new questions...\")\n",
    "            # Find job description\n",
    "            job = next((j for j in preprocessed_data['jobs'] if \n",
    "                       (current_company and current_company.lower() in j['company_name'].lower()) or \n",
    "                       (current_role and current_role.lower() in j['job_title'].lower())), {})\n",
    "            job_description = job.get('combined_text', '')\n",
    "            keywords = job.get('keywords', [])\n",
    "            \n",
    "            # Generate questions\n",
    "            gen_technical, gen_behavioral = generate_questions(job_description, keywords, num_technical=5, num_behavioral=3)\n",
    "            \n",
    "            if gen_technical or gen_behavioral:\n",
    "                new_set = {\n",
    "                    'job_title': current_role or 'Unknown Role',\n",
    "                    'company_name': current_company or 'Unknown Company',\n",
    "                    'seniority_level': job.get('seniority_level', 'Unknown'),\n",
    "                    'technical_questions': gen_technical[:5],\n",
    "                    'behavioral_questions': gen_behavioral[:3]\n",
    "                }\n",
    "                question_sets.append(new_set)\n",
    "                \n",
    "                # Save updated question sets\n",
    "                try:\n",
    "                    with open(UPDATED_QUESTION_SETS_PATH, 'w') as f:\n",
    "                        json.dump(question_sets, f, indent=2)\n",
    "                    print(f\"New question set saved to {UPDATED_QUESTION_SETS_PATH}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Oops, couldn't save the new question set: {e}\")\n",
    "                \n",
    "                print(\"\\nHere's your generated question set:\")\n",
    "                print(json.dumps(new_set, indent=2))\n",
    "            else:\n",
    "                # Fallback to a default question set\n",
    "                fallback_set = next((q_set for q_set in question_sets if 'data science' in q_set['job_title'].lower() or 'machine learning' in q_set['job_title'].lower()), None)\n",
    "                if fallback_set:\n",
    "                    print(\"\\nUnable to generate new questions due to API limits. Here's a default Data Science question set:\")\n",
    "                    print(json.dumps(fallback_set, indent=2))\n",
    "                else:\n",
    "                    print(\"\\nUnable to generate questions or find a suitable default set. Please try a different company or role.\")\n",
    "        \n",
    "        # Context-aware prompt\n",
    "        context_prompt = f\"You mentioned {current_company or current_role}. \"\n",
    "        print(f\"\\n{context_prompt}What next? Try 'more technical questions', 'more behavioral questions', 'interview tips', or specify a company/role.\")\n",
    "    \n",
    "    elif intent == 'more questions':\n",
    "        # Prompt for company/role if None\n",
    "        if not current_company and not current_role:\n",
    "            print(\"\\nI need a bit more info! Which company or role are you preparing for? (e.g., 'Upper Hand' or 'Data Science')\")\n",
    "            continue\n",
    "        \n",
    "        # Determine if technical or behavioral\n",
    "        num_technical = 2 if 'technical' in user_input.lower() else 0\n",
    "        num_behavioral = 1 if 'behavioral' in user_input.lower() else 0\n",
    "        if num_technical == 0 and num_behavioral == 0:\n",
    "            num_technical, num_behavioral = 2, 1  # Default to both\n",
    "        \n",
    "        # Find job description\n",
    "        job = next((j for j in preprocessed_data['jobs'] if \n",
    "                   (current_company and current_company.lower() in j['company_name'].lower()) or \n",
    "                   (current_role and current_role.lower() in j['job_title'].lower())), {})\n",
    "        job_description = job.get('combined_text', '')\n",
    "        keywords = job.get('keywords', [])\n",
    "        \n",
    "        # Generate questions\n",
    "        gen_technical, gen_behavioral = generate_questions(job_description, keywords, num_technical, num_behavioral)\n",
    "        if gen_technical or gen_behavioral:\n",
    "            print(\"\\nAdditional questions:\")\n",
    "            if gen_technical:\n",
    "                print(\"Technical:\")\n",
    "                for q in gen_technical:\n",
    "                    print(f\"- {q['question']} ({q['difficulty']})\")\n",
    "            if gen_behavioral:\n",
    "                print(\"Behavioral:\")\n",
    "                for q in gen_behavioral:\n",
    "                    print(f\"- {q['question']} ({q['difficulty']})\")\n",
    "        else:\n",
    "            # Fallback to existing questions\n",
    "            matched_set = next((q_set for q_set in question_sets if \n",
    "                               (current_company and current_company.lower() in q_set['company_name'].lower()) or \n",
    "                               (current_role and current_role.lower() in q_set['job_title'].lower())), None)\n",
    "            if matched_set:\n",
    "                print(\"\\nUnable to generate new questions due to API limits. Here's some from the existing set:\")\n",
    "                if num_technical > 0 and matched_set['technical_questions']:\n",
    "                    print(\"Technical:\")\n",
    "                    for q in matched_set['technical_questions'][:num_technical]:\n",
    "                        print(f\"- {q['question']} ({q['difficulty']})\")\n",
    "                if num_behavioral > 0 and matched_set['behavioral_questions']:\n",
    "                    print(\"Behavioral:\")\n",
    "                    for q in matched_set['behavioral_questions'][:num_behavioral]:\n",
    "                        print(f\"- {q['question']} ({q['difficulty']})\")\n",
    "            else:\n",
    "                print(\"\\nUnable to generate or find existing questions. Please try a different company or role.\")\n",
    "        \n",
    "        # Context-aware prompt\n",
    "        context_prompt = f\"You mentioned {current_company or current_role}. \"\n",
    "        print(f\"\\n{context_prompt}What next? Try 'more technical questions', 'more behavioral questions', 'interview tips', or specify a company/role.\")\n",
    "    \n",
    "    elif intent == 'interview tips':\n",
    "        tips = get_interview_tips(current_role)\n",
    "        print(\"\\nInterview tips:\")\n",
    "        for tip in tips:\n",
    "            print(f\"- {tip}\")\n",
    "        \n",
    "        # Context-aware prompt\n",
    "        context_prompt = f\"You mentioned {current_company or current_role or 'an interview'}. \"\n",
    "        print(f\"\\n{context_prompt}What next? Try 'more technical questions', 'more behavioral questions', 'interview tips', or specify a company/role.\")\n",
    "    \n",
    "    elif intent == 'greeting':\n",
    "        print(f\"\\nHey there! Ready to prep for an interview? Tell me something like 'I need to prepare for an Upper Hand interview' or 'interview tips'.\")\n",
    "        if current_company or current_role:\n",
    "            print(f\"You mentioned {current_company or current_role}. Want questions or tips for that? (e.g., 'prepare for {current_company or current_role} interview')\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nI didn't quite understand. Try something like 'I need to prepare for an Upper Hand interview', 'more questions', or 'interview tips'.\")\n",
    "        if current_company or current_role:\n",
    "            print(f\"You mentioned {current_company or current_role}. Want questions or tips for that? (e.g., 'prepare for {current_company or current_role} interview')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be267e-795e-4908-a342-74ce537a1207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
